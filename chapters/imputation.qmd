---
title: Imputation
message: false
warning: false
---

```{r}
#| echo: false
#| warning: false
#| message: false
library(tidyverse)
  options(quarto.max_rows = 5)
```

Imputation is a statistical technique that fills in missing or incomplete data by estimating values from existing information, but its controversial nature arises from the introduction of artificial data, potentially impacting analysis outcomes as newly completed data is assigned more weight. In this chapter we will cover types of missing data and different ways of dealing with it.

> As in medicine the best solution to missing data is prevention!

## Types of Missing Data

Understanding the type of missing data is crucial as it can guide the appropriate choice of imputation methods or handling strategies to minimize potential biases in the analysis.

1.  **Missing Completely at Random (MCAR)**: The missingness in the data is entirely random, and the probability of missing data is the same for all observations, regardless of observed or unobserved values. MCAR is an ideal scenario, as missing data does not depend on any other variables in the dataset. For example, thermometer battery dying and not recording temperature for a session.

2.  **Missing at Random (MAR)**: MAR occurs when the missingness is related to observed variables in the dataset, but not to the unobserved values. We might see MAR if males are less likely to answer questions about mental health then women in a survey.

3.  **Missing Not at Random (MNAR)**: In MNAR, the missingness is related to the unobserved values. The probability of missing data depends on the variables that are missing. For instance, avid smokers might skip a section asking about lung health which would result in biased survey results.

4.  **Missing by Design**: Missing by design occurs when specific data points are intentionally missing, often as part of the study design or data collection process. In such cases, the missing data is systematic and has a purpose.

Before addressing missing data, it is often essential to distinguish between different types of missingness. Explicitly marking missing data as NA in R helps in identifying the patterns and dealing with the missing values appropriately.

## Dealing with Missing Data

There are several ways to handle missing data:

1.  **Keep it**: In some cases, it might be appropriate to retain the missing data if the missingness does not significantly affect the analysis.

2.  **Drop it (List-wise Deletion or Complete Case Analysis)**: This approach involves removing rows with missing data. It's simple and can be suitable if missing data is minimal and random. However, it can lead to information loss, potential bias, and reduced sample size. Despite these drawbacks, it's a common method in quantitative research due to its simplicity.

3.  **Impute it**: Imputation involves estimating missing values based on observed data, which allows for a complete dataset and ensures that all cases are retained for analysis. However, if not done correctly will introduce bias.

4.  **Set as Dummy or a Factor**: Sometimes, missing values can be treated as a separate category. This can be done by creating a dummy variable or converting the variable into a factor. This approach acknowledges the missing data and incorporates it into the analysis as a distinct group.

Imputation, while a powerful tool, must be applied judiciously as it modifies the original dataset and can substantially influence analysis outcomes. It's essential to comprehend the reasons behind the missing data, the assumptions involved, and the justification for using imputation in the specific context of your analysis.

> Imputation should never be a default choice, but a well-considered strategy.

### Explicitly Handling Missing Data with `complete()`

When working with datasets, it's crucial to understand that missing values aren't always explicitly identifiable. These implicit absences can misleadingly suggest data completeness, emphasizing the necessity for appropriate identification and handling. The `tidyr` package's `complete()` function offers a robust solution.

The `complete()` function generates a new dataframe featuring all potential combinations of specified columns, thereby assuring data comprehensiveness. This process, complemented by filling absent combinations with default values, mitigates the risk of implicit missing data.

Take, for instance, a dataset tracking four students attending various classes over three days. Initially, this dataset might seem comprehensive. However, only the attending students were recorded, leaving a data gap for absentees.

In this case, we employ `complete()` to create `complete_df`, a new dataframe that encapsulates all conceivable combinations of `student_id`, `day`, and `class.` This method ensures accurate recording of each student's attendance for every class on each day, irrespective of the initial data's shortcomings. The "present" column's missing values default to `FALSE`, clearly denoting unrecorded attendance.

```{r}
#| code-fold: true
# `tribble()` is a function to create a data frame in a readable
# format
df <- tribble(
~day, ~class, ~student_id, ~present,
1, "English", 1, T,
1, "English", 2, T,
1, "English", 4, T,
1, "Science", 2, T,
2, "Math", 1, T,
2, "Math", 2, T,
2, "Math", 4, T,
2, "English", 4, T,
2, "English", 1, T,
3, "Math", 1, T,
3, "Math", 2, T,
3, "Math", 1, T
)
```
```{r}
#| classes: output
#| echo: false
df
```

```{r}
# Creating a complete dataframe with all possible combinations of
# `student_id` and nested combinations of `day` and `class`
complete_df <- df %>%
complete(
# `full_seq()` generates a sequence of student IDs, using the number
# of unique student IDs as the maximum value
student_id = full_seq(student_id, 1),
# `nesting()` creates only combinations that already exist in the data
nesting(day, class),
# Fills missing attendance data with `FALSE`
fill = list(present = FALSE),
# Limit the `fill` to only the newly created (i.e. previously
# implicit)
explicit = FALSE
) %>%
# Orders the resulting data frame by `day`, `class`, `student_id`, and
# `present`
arrange(day, class, student_id, present)
```

```{r}
#| classes: output
#| echo: false
print(complete_df, n = 100)
```

By using `nesting()`, which creates all combinations present data, within `complete()`, we explicitly handle missing data, creating a comprehensive nested dataset suitable for further analysis. This approach guarantees that our analysis is based on a more complete and reliable dataset, providing accurate attendance across different classes and days.

### Simple Imputations

To explore different imputations we will use "airquality" dataset that contains daily measurements of air pollutants and weather conditions in New York City during a five-month period in 1973. It includes data on ozone concentration, solar radiation, temperature, wind speed, and relative humidity. To simplify the example, we will remove all rows with missing `Solar.R` values and focus on `Ozone`. We will also define `head_na` to view the values that were imputed.


```{r}
#| label: fig-missing_pattern
# Remove rows with missing values in `Solar.R`.
airquality <- drop_na(airquality, Solar.R)
# `md.pattern` makes a matrix of missing values. `invisible` to only
# show plot, without matrix output.
invisible(mice::md.pattern(airquality))
head_na <- function(data, n = 5) {
data %>%
filter(is.na(Ozone)) %>%  # Filter rows with NA in `Ozone`.
select(-Ozone) %>%        # Exclude `Ozone` column from the results.
head(n)                   # Display the first `n` rows.
}
head(airquality)
```

Another good way is to use a premade function from `visdat` called `vismiss`. It will show distribution of missing data, you can prearrange data and facet to better identify missing data. The graph below is arranged by day and each months has its own facet, so we can see a pattern of missing values. Looks like June (6) has many missing values for Ozone.

```{r}
#| label: fig-vis_miss
airquality %>%
  arrange(Month, Day) %>%
  visdat::vis_miss(facet = Month)
```

#### Fixed Value Imputation

Missing values are replaced with a predetermined constant value. This method is simple and useful when you believe the fixed value reasonably represents the missing data.

##### Dealing with Missing Data

You can pair fixed value imputation with 0 and add a column indicating missing values. This approach allows you to include missing values in your regression analysis by adding a coefficient for missing data.

#### Mean and Median Imputation

Missing values are replaced with the mean or median of the non-missing data in the same column. Using the mean is effective when data follow a normal distribution, but it can be affected by outliers, leading to biased imputations. In contrast, using the median is more robust to outliers and suitable for skewed or extreme data.

#### Fill

In some scenarios, it's rational to replace missing data with either preceding or succeeding values. This approach is particularly effective with datasets where the next available value logically substitutes the missing ones, such as in time-series or ordered data.

I recommend familiarizing yourself with `coalesce`, which let's you replace missing values with a predefined value or with values from another column.

```{r}
airquality %>%
arrange(Month, Day) %>%
mutate(
# Impute with a fixed value (0 in this case).
imp_fixed = coalesce(Ozone, 0),
Ozone_missing = is.na(Ozone),
# Impute with the mean.
imp_mean = coalesce(Ozone, round(mean(Ozone, na.rm = TRUE), 2)),
# Impute with the median.
imp_median = coalesce(Ozone, median(Ozone, na.rm = TRUE)),
imp_fill = Ozone,
.keep = "used" # Keep only "used" columns.
) %>%
# Fills missing values with the most recent non-missing value above.
fill(imp_fill, .direction = "down") %>%
head_na()
```

Remember that the choice of imputation method can significantly impact the results of your analysis. Always consider the nature of your data, the distribution of missingness, and the potential implications of each method before making a decision.

#### K-Nearest Neighbors (KNN)

```{r}
# KNN imputation using the 'VIM' package
library(VIM)
airquality_knn <- kNN(airquality)

airquality_knn %>%
  slice(which(is.na(airquality$Ozone))) %>%
  select("Ozone") %>%
  head(n=5)
```

KNN imputation can be a good choice when the data have a complex structure that simple methods can't capture. It uses the relationships between variables to estimate missing values.

#### Regression

```{r}
# Fit a linear regression model
model <- lm(Ozone ~ ., data = airquality)

# Predict missing values
predicted_values <- predict(model, newdata = airquality)

# Replace missing values with predicted values
airquality %>% 
  mutate(
    Ozone = Ozone,
    imp_lm = ifelse(is.na(Ozone), predicted_values, Ozone),
    .keep = "used"
  ) %>% 
  head_na()
```

Regression imputation can be useful when there are relationships between variables that can be captured by a regression model.

#### Forest

```{r}
# Install and load the missForest package
library(missForest)

airquality %>%
  mutate(
    Ozone = Ozone,
    imp_forest = missForest(.)$ximp$Ozone,
    .keep = "used"
  ) %>%
  head_na()
```

Tree-based methods like Random Forests can handle complex data structures and can be a good choice when relationships between variables are non-linear or involve interactions. However, they may not perform well with small sample sizes or sparse data.

Remember, each of these methods has its own strengths and weaknesses, and the choice of method should be guided by the nature of your data and the specific requirements of your analysis. Always check the assumptions of the imputation method you're using and consider the potential impact on your results.

### Best-Worst case and Worst-Best case

A straightforward method to assess the impact of missing data is to replace it with both the worst and best possible outcomes. In clinical trials, it's typical to assume the control group achieves a beneficial outcome, calculated as the mean plus 2 standard deviations, while the treatment group experiences a detrimental outcome, calculated as the mean minus 2 standard deviations. This method creates two new data series: one reflecting an optimistic scenario and the other a pessimistic one, known as the best-worst case scenario.[c] Conversely, the worst-best case scenario reverses these assumptions.

For our purposes, we will apply this method by creating two new columns in our dataset, imputing Ozone values using high (mean + 2 standard deviations) and low (mean - 2 standard deviations) estimates for each month to analyze how these extremes might affect our results.


```{r}
airquality %>%
  mutate(
    Ozone_best = coalesce(Ozone, mean(Ozone,na.rm = T) + 2 *sd(Ozone, na.rm = T)),
    Ozone_worst = coalesce(Ozone, mean(Ozone, na.rm = T) - 2 *sd(Ozone, na.rm = T)),
    .by = Month
  ) %>%
  summarize(
    Ozone_best = round(mean(Ozone_best),0),
    Ozone = round(mean(Ozone, na.rm = T),0),
    Ozone_worst = round(mean(Ozone_worst),0),
    .by = Month
  )
```

### Multiple Imputations

Now, listen closely, imputing can be better then dropping the data! Wait what? Yeh, because instead of dropping the data you preserve it! However, there is a method to this. [@jakobsenWhenHowShould2017]

Multiple imputation is a statistical technique that has been increasingly utilized since its inception in the early 1970s. It is a simulation-based method designed to address the issue of missing data in research studies. The process of multiple imputation is carried out in three main steps:

1.  **Imputation Step**: In this initial stage, missing values in the dataset are identified and replaced with a set of plausible values, creating multiple completed datasets. These plausible values, or 'imputations', are generated based on a chosen imputation model. To reduce sampling variability from the imputation process, it is often preferable to generate minimum of 5 datasets. A good rule of thumb is number of iterations equals percentage of missing data.

2.  **Completed-Data Analysis (Estimation) Step**: Once the imputed datasets are created, the desired analysis is performed separately on each dataset. For instance, if 5 datasets were generated during the imputation step, 5 separate analyses would be conducted.

3.  **Pooling Step**: The results obtained from each completed-data analysis are then combined into a single multiple-imputation result. Each analysis result is considered to have the same statistical weight, so there is no need for a weighted meta-analysis.

It is crucial to ensure compatibility between the imputation model and the analysis model, or that the imputation model is more general than the analysis model. This means that the imputation model should include more independent covariates than the analysis model. For instance, if the analysis model includes significant interactions, then the imputation model should include them as well. Similarly, if the analysis model uses a transformed version of a variable, then the imputation model should use the same transformation.

> It's important to note that the multiple imputations assume that the missing data are Missing At Random (MAR).

To help you make a decision, answer the following questions. If you respond "yes" to any of them, use only the observed data. However, discuss and report the extent of the missing data and its limitations. Also, consider including best-worst and worst-best case analyses in your report.

1. Is it valid to ignore missing data (below 5%)? If yes, the missing data is negligible in this case.
2. Is a large proportion of missing data (above 40%) significant? If yes, the missing data is substantial when it exceeds this threshold.
3. Is data only missing in the dependent variable? If yes, only the dependent variable values are missing.
4. Is the MCAR assumption plausible? If yes, the data is missing completely at random.
5. Is the MNAR assumption plausible? If yes, the data is missing not at random.

If all the answers are "no," consider using multiple imputation to handle the missing data.



<!-- ![](images/imputation_flow.png) -->

#### MICE (Multivariate Imputation by Chained Equations)

The `mice` package in R is a powerful tool for handling missing data through multiple imputation. It uses the Multivariate Imputation by Chained Equations (MICE) algorithm, which creates multiple imputations (replacement values) for multivariate missing data. The basic idea behind the algorithm is to treat each variable that has missing values as a dependent variable in regression and treat the others as independent (predictors). You can learn more about MICE in [this paper](https://www.researchgate.net/publication/44203418_MICE_Multivariate_Imputation_by_Chained_Equations_in_R).

MICE stands for *Multivariate Imputation via Chained Equations*, and it's one of the most common packages for R users. It assumes the missing values are missing at random (MAR).

First, install and load the `mice` package:

```{r}
library(mice)
```

The R `mice` packages provide many [univariate imputation methods](https://www.rdocumentation.org/packages/mice/versions/3.14.0/topics/mice), but we'll use only a handful. First, let's import the package and subset only the numerical columns to keep things simple. Only the `Age` attribute contains missing values:

Onto the imputation now. We'll use the following MICE imputation methods:

The `mice` function supports several imputation methods. The choice of method depends on the nature of variables. Here are a few commonly used methods:

-   `"pmm"`: Predictive mean matching. Useful for numeric data.
-   `"cart"`: Classification and regression trees.
-   `"laso.norm"`: Lasso linear regression.
-   `"logreg"`: Logistic regression. Useful for binary data.
-   `"polyreg"`: Polytomous logistic regression. Useful for ordered categorical data.
-   `"polr"`: Proportional odds model. Useful for ordered categorical data.

Following imputation, each dataset can be analyzed independently. Let's perform some of these imputations! The `mice::complete` function is utilized to create a fully imputed dataset from a `mice` object, with the imputation `method` specified and `printFlag = FALSE` employed to prevent output from being displayed in the console. Finally, `$Ozone` extracts the column.


```{r}
set.seed(1)
airquality %>% 
  mutate(
  Ozone = Ozone,
  imp_pmm = mice::complete(mice(., method = "pmm", printFlag = FALSE))$Ozone,
  imp_pmm2 = mice::complete(mice(., method = "pmm", printFlag = FALSE))$Ozone,
  imp_cart = mice::complete(mice(., method = "cart", printFlag = FALSE))$Ozone,
  imp_cart2 = mice::complete(mice(., method = "cart", printFlag = FALSE))$Ozone,
  imp_lasso = mice::complete(mice(., method = "lasso.norm", printFlag = FALSE))$Ozone,
  imp_lasso2 = mice::complete(mice(., method = "lasso.norm", printFlag = FALSE))$Ozone,
  .keep = "used" # Keep only the variables used in mutate call
) %>%
head_na()
```

Note that running the same specification a second time yields a different result. This variation occurs because the algorithms introduce randomness, leading to uncertainty in imputation (instead of a definitive imputation value of 20, it's more accurate to expect a range, such as between 18 and 22). To accommodate this and incorporate the inherent uncertainty, you can utilize the `mice()` function to carry out multiple imputations:

```{r}
# Perform multiple imputation
imp <- mice(airquality, 
            m = 5, # number of complete datasets to generate
            method = "pmm", # specifies method for imputation
            seed = 1337, # set seed for reproducibility
            printFlag = FALSE) # don't print history on console
```

Now we can fit a linear regression model and summarize the combined results from the five imputed datasets:

```{r}
# Fit a linear model on each imputed dataset
fit <- with(imp, lm(Ozone ~ Solar.R + Wind + Temp + Month)) # replace y, x1, x2 with your dependent and independent variables

# Pool the results of these models
pool <- pool(fit)
summary(pool)
```

You can also use `gtsummary` to create a summary table, which we will cover in [Make Tables](chapters/tables.qmd) section. Here `tbl_regression` automatically pools results.

```{r}
library(gtsummary)
tbl_regression(fit)
```

Imputation is a valuable tool for handling missing data, but it should be used judiciously and based on a thorough understanding of the data and the analysis objectives. Responsible imputation ensures that any assumptions made during the process align with the data generation process and results in more reliable and meaningful data analysis.

## Summary

In this chapter, we delved into the use of imputation as a technique for 
addressing missing data in statistical analysis, 
explored various types of missing data, and discussed several strategies for managing them.
The chapter highlighted essential tools in R for this purpose and examined a range of imputation methods. 
We especially focused on responsible imputation practices for trustworthy data analysis. 
In the next section, we will shift our attention to the practices of Reproducible Research.

### Table of Imputations

The following table allows you to compare the variation in results produced by each imputation method.

```{r, include=knitr::is_html_output()}
#| echo: false
#| eval: true
set.seed(1)
airquality %>%
  mutate(
    imp_fixed = replace(Ozone, is.na(Ozone), 0), # Impute with a fixed value (0 in this case)
    Ozone_missing = is.na(Ozone),
    imp_mean = replace(Ozone, is.na(Ozone), round(mean(Ozone, na.rm = TRUE), 2)), # Impute with the mean
    imp_fill = Ozone,
    imp_median = replace(Ozone, is.na(Ozone), median(Ozone, na.rm = TRUE)), # Impute with the median
    imp_forest = missForest(.)$ximp$Ozone,
    imp_lm = ifelse(is.na(Ozone), predicted_values, Ozone),
    imp_knn = airquality_knn$Ozone,
    # imp_mlh = airquality_mlh$Ozone,
    imp_pmm = complete(mice(., method = "pmm", printFlag = FALSE))$Ozone,
    imp_cart = complete(mice(., method = "cart", printFlag = FALSE))$Ozone,
    imp_lasso = complete(mice(., method = "lasso.norm", printFlag = FALSE))$Ozone,
    .keep = "used" 
  ) %>%
  fill(imp_fill, .direction = "down") %>% 
  filter(is.na(Ozone)) %>%
  select(-Ozone) %>%
  mutate(across(everything(), ~round(.,1))) %>%
  DT::datatable(
  options = list(pageLength = 10, scrollX = TRUE), 
  rownames = FALSE, 
  class = 'cell-border stripe' 
)
```

```{r, include=knitr::is_latex_output()}
set.seed(1)
airquality %>%
  mutate(
    imp_fixed = replace(Ozone, is.na(Ozone), 0), # Impute with a fixed value (0 in this case)
    Ozone_missing = is.na(Ozone),
    imp_mean = replace(Ozone, is.na(Ozone), round(mean(Ozone, na.rm = TRUE), 2)), # Impute with the mean
    imp_fill = Ozone,
    imp_median = replace(Ozone, is.na(Ozone), median(Ozone, na.rm = TRUE)), # Impute with the median
    imp_forest = missForest(.)$ximp$Ozone,
    imp_lm = ifelse(is.na(Ozone), predicted_values, Ozone),
    imp_knn = airquality_knn$Ozone,
    # imp_mlh = airquality_mlh$Ozone,
    imp_pmm = complete(mice(., method = "pmm", printFlag = FALSE))$Ozone,
    imp_cart = complete(mice(., method = "cart", printFlag = FALSE))$Ozone,
    imp_lasso = complete(mice(., method = "lasso.norm", printFlag = FALSE))$Ozone,
    .keep = "used" 
  ) %>%
  fill(imp_fill, .direction = "down") %>% 
  filter(is.na(Ozone)) %>%
  select(-Ozone) %>%
  mutate(across(everything(), ~round(.,1))) %>%
  gt::gt()
```
